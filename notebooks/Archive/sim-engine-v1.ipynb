{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a7d5c4-f6b6-4617-8bad-f2a954d4448f",
   "metadata": {},
   "source": [
    "# Seldon Labs Game Engine V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497b44f-7a28-4e0e-8572-f0d5f228e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from networkx.drawing.nx_agraph import graphviz_layout  # Improved layout\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631763f-c656-418b-a539-c91964c39200",
   "metadata": {},
   "source": [
    "### Just for Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720f481-ed3a-4c54-8d37-3f034afd5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy:\n",
    "    \"\"\"Represents a player's strategy, supporting both pure and mixed strategies.\"\"\"\n",
    "    def __init__(self, strategy_name, probabilities=None):\n",
    "        self.strategy_name = strategy_name\n",
    "        self.probabilities = probabilities or {}  # Maps actions to probabilities\n",
    "\n",
    "    def choose_action(self):\n",
    "        \"\"\"Chooses an action based on the mixed strategy probabilities.\"\"\"\n",
    "        actions, probs = zip(*self.probabilities.items())\n",
    "        return random.choices(actions, probs)[0]  # Probabilistic choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0effe-0437-4e25-a5b4-487b6bb3d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Represents a game state, supporting simultaneous and sequential moves.\"\"\"\n",
    "    def __init__(self, players):\n",
    "        self.players = players  # A set of players acting at this node\n",
    "        self.actions = {}  # Maps action tuples to child nodes\n",
    "        self.payoff = None  # Stores outcome if terminal\n",
    "\n",
    "    def add_action(self, actions, child_node):\n",
    "        \"\"\"Adds an action tuple leading to a child node.\"\"\"\n",
    "        self.actions[tuple(actions)] = child_node\n",
    "\n",
    "class Game:\n",
    "    \"\"\"Represents a game supporting both mixed strategies and simultaneous moves.\"\"\"\n",
    "    def __init__(self, root_players):\n",
    "        if isinstance(root_players, str):\n",
    "            root_players = [root_players]  # Convert to list if single player\n",
    "        self.root = Node(set(root_players))\n",
    "        self.current_nodes = [self.root]  # Track nodes that need expansion\n",
    "        self.players = set(root_players)\n",
    "\n",
    "    def add_moves(self, players, actions_list):\n",
    "        \"\"\"\n",
    "        Expands the game tree with moves for one or more players.\n",
    "        - `players`: Single player (str) or multiple players (list).\n",
    "        - `actions_list`: If multiple players, provide a list of lists of actions.\n",
    "        \"\"\"\n",
    "        if isinstance(players, str):\n",
    "            players = [players]  # Convert to list\n",
    "        if isinstance(actions_list[0], str):\n",
    "            actions_list = [actions_list]  # Wrap in list for consistency\n",
    "        \n",
    "        new_nodes = []\n",
    "        for node in self.current_nodes:\n",
    "            action_combinations = list(itertools.product(*actions_list))\n",
    "            for actions in action_combinations:\n",
    "                child_node = Node(set(players))\n",
    "                node.add_action(actions, child_node)\n",
    "                new_nodes.append(child_node)\n",
    "        \n",
    "        self.current_nodes = new_nodes  # Update frontier\n",
    "        self.players.update(players)\n",
    "\n",
    "    def add_outcomes(self, payoffs):\n",
    "        \"\"\"Assigns payoffs to terminal nodes.\"\"\"\n",
    "        if len(self.current_nodes) != len(payoffs):\n",
    "            raise ValueError(\"Number of outcomes must match terminal nodes.\")\n",
    "\n",
    "        for node, payoff in zip(self.current_nodes, payoffs):\n",
    "            node.payoff = payoff\n",
    "\n",
    "    def display_tree(self, node=None, depth=0):\n",
    "        \"\"\"Recursively prints the game tree for debugging.\"\"\"\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        indent = \"    \" * depth\n",
    "        if node.actions:\n",
    "            print(f\"{indent}{', '.join(node.players)} moves:\")\n",
    "            for actions, child in node.actions.items():\n",
    "                action_str = \" | \".join(actions)\n",
    "                print(f\"{indent}  ├─ {action_str}\")\n",
    "                self.display_tree(child, depth + 1)\n",
    "        else:\n",
    "            print(f\"{indent}  (Payoff: {node.payoff})\")\n",
    "\n",
    "    def visualize_tree(self):\n",
    "        \"\"\"Visualizes the game tree with improved spacing using Graphviz.\"\"\"\n",
    "        graph = nx.DiGraph()\n",
    "        node_labels = {}\n",
    "        \n",
    "        def add_edges(node, parent=None, action_label=None):\n",
    "            \"\"\"Recursively add nodes and edges to the graph.\"\"\"\n",
    "            node_id = id(node)  # Unique identifier\n",
    "            label = f\"{', '.join(node.players)}\" if node.actions else f\"Payoff: {node.payoff}\"\n",
    "            node_labels[node_id] = label\n",
    "\n",
    "            if parent is not None:\n",
    "                graph.add_edge(parent, node_id, action=action_label)\n",
    "\n",
    "            for action, child in node.actions.items():\n",
    "                add_edges(child, node_id, action)\n",
    "\n",
    "        add_edges(self.root)\n",
    "\n",
    "        # Use Graphviz DOT layout for better hierarchy\n",
    "        pos = graphviz_layout(graph, prog=\"dot\")\n",
    "\n",
    "        # Draw graph\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        nx.draw(graph, pos, with_labels=True, labels=node_labels, node_color=\"lightblue\", edge_color=\"black\", \n",
    "                node_size=3000, font_size=8, font_weight=\"bold\", arrowsize=15)\n",
    "\n",
    "        # Add action labels on edges\n",
    "        edge_labels = {(u, v): data[\"action\"] for u, v, data in graph.edges(data=True)}\n",
    "        nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_size=8, \n",
    "                                     bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.8))\n",
    "\n",
    "        plt.title(\"Game Tree Visualization\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118f411-cded-468a-b5d1-acb582b4e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "game = Game(root_players=[\"China\", \"US\"])  # Both move simultaneously\n",
    "game.add_moves(players=[\"China\", \"US\"], actions_list=[[\"Tariff\", \"No Tariff\"], [\"Tariff\", \"No Tariff\"]])\n",
    "\n",
    "outcomes = [\n",
    "    (-6, -6),  # Both tariff\n",
    "    (0, -10),  # China tariffs, US does not\n",
    "    (-10, 0),  # China does not tariff, US does\n",
    "    (-1, -1)   # Neither tariffs\n",
    "]\n",
    "game.add_outcomes(outcomes)\n",
    "\n",
    "game.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d12b373-b49c-4896-a0d8-628f46e197f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.visualize_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140f64e-bb9d-418d-89f6-cd3ff1119eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521d7b0-f252-4f8d-8ada-a684047ddb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "game = Game(root_players=[\"China\"])  # Both move simultaneously\n",
    "game.add_moves(players=[\"US\"], actions_list=[[\"Tariff\", \"No Tariff\"]])\n",
    "game.add_moves(players=[\"China\"], actions_list=[[\"Tariff\", \"No Tariff\"]])\n",
    "\n",
    "outcomes = [\n",
    "    (-6, -6),  # Both tariff\n",
    "    (0, -10),  # China tariffs, US does not\n",
    "    (-10, 0),  # China does not tariff, US does\n",
    "    (-1, -1)   # Neither tariffs\n",
    "]\n",
    "game.add_outcomes(outcomes)\n",
    "\n",
    "game.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4c574-3d35-4fc9-8185-b0e5daecd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.visualize_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0d942-4bbb-4122-baae-536061656bfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Good Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bf303-8f38-450e-91b2-1e305abc9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "class Node:\n",
    "    \"\"\"Represents a game state, supporting sequential moves.\"\"\"\n",
    "    def __init__(self, players=None):\n",
    "        self.players = players if players else set()\n",
    "        self.actions = {}  # Maps action names to child nodes\n",
    "        self.payoff = None  # Stores outcome if terminal\n",
    "\n",
    "    def add_action(self, action, child_node):\n",
    "        \"\"\"Adds an action leading to a child node.\"\"\"\n",
    "        self.actions[action] = child_node\n",
    "\n",
    "class Game:\n",
    "    \"\"\"Represents a game theory structure with players, actions, and payoffs.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "        self.current_nodes = [self.root]  # Track leaf nodes for expansion\n",
    "    \n",
    "    def add_moves(self, player, actions):\n",
    "        \"\"\"Adds moves for a player at all current leaf nodes.\"\"\"\n",
    "        new_nodes = []\n",
    "        for node in self.current_nodes:\n",
    "            node.players.add(player)\n",
    "            for action in actions:\n",
    "                child_node = Node()\n",
    "                node.add_action(action, child_node)\n",
    "                new_nodes.append(child_node)\n",
    "        self.current_nodes = new_nodes\n",
    "    \n",
    "    def add_outcomes(self, outcomes):\n",
    "        \"\"\"Assigns payoffs to the current leaf nodes.\"\"\"\n",
    "        if len(outcomes) != len(self.current_nodes):\n",
    "            raise ValueError(\"Number of outcomes must match the number of terminal nodes.\")\n",
    "        for node, payoff in zip(self.current_nodes, outcomes):\n",
    "            node.payoff = payoff\n",
    "    \n",
    "    def display_tree(self):\n",
    "        \"\"\"Recursively prints the game tree.\"\"\"\n",
    "        def recurse(node, depth=0):\n",
    "            payoff_text = f\", Payoff: {node.payoff}\" if node.payoff is not None else \"\"\n",
    "            print(\"  \" * depth + f\"Players: {node.players}{payoff_text}\")\n",
    "            for action, child in node.actions.items():\n",
    "                print(\"  \" * depth + f\"Action: {action}\")\n",
    "                recurse(child, depth + 1)\n",
    "        recurse(self.root)\n",
    "    \n",
    "    def visualize_tree(self):\n",
    "        \"\"\"Visualizes the game tree with improved spacing using Graphviz.\"\"\"\n",
    "        graph = nx.DiGraph()\n",
    "        node_labels = {}\n",
    "        \n",
    "        def add_edges(node, parent=None, action_label=None):\n",
    "            \"\"\"Recursively add nodes and edges to the graph.\"\"\"\n",
    "            node_id = id(node)  # Unique identifier\n",
    "            label = f\"{', '.join(node.players)}\" if node.actions else f\"Payoff: {node.payoff}\"\n",
    "            node_labels[node_id] = label\n",
    "\n",
    "            if parent is not None:\n",
    "                graph.add_edge(parent, node_id, action=action_label)\n",
    "\n",
    "            for action, child in node.actions.items():\n",
    "                add_edges(child, node_id, action)\n",
    "\n",
    "        add_edges(self.root)\n",
    "\n",
    "        # Use Graphviz DOT layout for better hierarchy\n",
    "        pos = graphviz_layout(graph, prog=\"dot\")\n",
    "\n",
    "        # Draw graph\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        nx.draw(graph, pos, with_labels=True, labels=node_labels, node_color=\"lightblue\", edge_color=\"black\", \n",
    "                node_size=3000, font_size=8, font_weight=\"bold\", arrowsize=15)\n",
    "\n",
    "        # Add action labels on edges\n",
    "        edge_labels = {(u, v): data[\"action\"] for u, v, data in graph.edges(data=True)}\n",
    "        nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_size=8, \n",
    "                                     bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.8))\n",
    "\n",
    "        plt.title(\"Game Tree Visualization\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866566d-01df-4a63-a055-27c6a1deace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new game instance\n",
    "game = Game()\n",
    "\n",
    "# Add moves for China and the US\n",
    "game.add_moves(player=\"China\", actions=[\"Tariff\", \"No Tariff\"])\n",
    "game.add_moves(player=\"US\", actions=[\"Tariff\", \"No Tariff\"])\n",
    "\n",
    "# Define the outcomes/payoffs for the terminal nodes\n",
    "outcomes = [\n",
    "    (-6, -10),  # Both impose tariffs\n",
    "    (0, -6),  # China tariffs, US does not\n",
    "    (-10, 0),  # China does not tariff, US does\n",
    "    (-1, -1),   # Neither imposes tariffs\n",
    "]\n",
    "game.add_outcomes(outcomes)\n",
    "\n",
    "# Display the game tree structure\n",
    "game.display_tree()\n",
    "\n",
    "# Visualize the game tree\n",
    "game.visualize_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47b549-ab2f-4f2e-a588-1310c2ad2e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, game):\n",
    "        \"\"\"Initialize with a game instance.\"\"\"\n",
    "        if not isinstance(game, Game):\n",
    "            raise TypeError(\"Solver expects an instance of Game.\")\n",
    "        self.game = game\n",
    "        self.equilibrium = {}\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"Base method to be overridden by specific solvers.\"\"\"\n",
    "        raise NotImplementedError(\"Solve method must be implemented in subclasses.\")\n",
    "\n",
    "    def get_equilibrium(self):\n",
    "        \"\"\"Return the computed equilibrium.\"\"\"\n",
    "        return self.equilibrium\n",
    "\n",
    "class BackwardInductionSolver(Solver):\n",
    "    def __init__(self, game):\n",
    "        \"\"\"Initialize the backward induction solver with a game.\"\"\"\n",
    "        super().__init__(game)\n",
    "        self.optimal_actions = {}  # Dictionary to store optimal actions at each node\n",
    "        self.node_values = {}      # Dictionary to store computed values for each node\n",
    "        # Debug mode to print detailed information during solving\n",
    "        self.debug = False\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"Solve the game using backward induction.\"\"\"\n",
    "        # Start from the root and solve recursively\n",
    "        self._backward_induction(self.game.root)           \n",
    "        return self.optimal_actions\n",
    "\n",
    "    def _backward_induction(self, node, depth=0):\n",
    "        \"\"\"\n",
    "        Recursive backward induction algorithm.\n",
    "        Returns the value (payoff) of the current node.\n",
    "        \n",
    "        Parameters:\n",
    "        node: Current game node\n",
    "        depth: Current depth in the tree (for debugging)\n",
    "        \"\"\"\n",
    "        node_id = id(node)\n",
    "        \n",
    "        # Base case: terminal node (no actions)\n",
    "        if not node.actions:\n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + f\"Terminal node with payoff: {node.payoff}\")\n",
    "            self.node_values[node_id] = node.payoff\n",
    "            return node.payoff\n",
    "        \n",
    "        # Get the player making the decision at this node\n",
    "        if not node.players:\n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + \"No players at this node\")\n",
    "            return None\n",
    "        \n",
    "        current_player = next(iter(node.players))\n",
    "        if self.debug:\n",
    "            print(\"  \" * depth + f\"Player {current_player} at depth {depth}\")\n",
    "        \n",
    "        # Determine index of current player in payoff tuples\n",
    "        # For your specific game with players \"China\" and \"US\"\n",
    "        player_idx = 0 if current_player == \"China\" else 1\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"  \" * depth + f\"Player index: {player_idx}\")\n",
    "        \n",
    "        # Get values of all children\n",
    "        best_payoff = float('-inf')\n",
    "        best_action = None\n",
    "        best_value = None\n",
    "        \n",
    "        for action, child_node in node.actions.items():\n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + f\"Trying action: {action}\")\n",
    "            \n",
    "            child_value = self._backward_induction(child_node, depth + 1)\n",
    "            \n",
    "            if child_value is None:\n",
    "                continue\n",
    "            \n",
    "            # Extract the current player's payoff from the tuple\n",
    "            player_payoff = child_value[player_idx]\n",
    "            \n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + f\"Action {action} gives payoff {player_payoff} to {current_player}\")\n",
    "            \n",
    "            if player_payoff > best_payoff:\n",
    "                best_payoff = player_payoff\n",
    "                best_action = action\n",
    "                best_value = child_value\n",
    "                \n",
    "                if self.debug:\n",
    "                    print(\"  \" * depth + f\"New best action: {best_action} with payoff {best_payoff}\")\n",
    "        \n",
    "        # Store optimal action for this node\n",
    "        if best_action is not None:\n",
    "            self.optimal_actions[node_id] = best_action\n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + f\"Optimal action for node {node_id}: {best_action}\")\n",
    "        \n",
    "        # Store node value\n",
    "        self.node_values[node_id] = best_value\n",
    "        \n",
    "        return best_value\n",
    "    \n",
    "    def get_subgame_perfect_equilibrium(self):\n",
    "        \"\"\"Return the subgame perfect equilibrium strategies.\"\"\"\n",
    "        if not self.optimal_actions:\n",
    "            self.solve()\n",
    "        \n",
    "        # Format the equilibrium strategies by player\n",
    "        equilibrium = {}\n",
    "        \n",
    "        # Traverse the tree to determine which nodes are reachable\n",
    "        def traverse(node, path=[]):\n",
    "            node_id = id(node)\n",
    "            \n",
    "            # Skip terminal nodes\n",
    "            if not node.actions:\n",
    "                return\n",
    "            \n",
    "            # For each player at this node, record their optimal action\n",
    "            for player in node.players:\n",
    "                if player not in equilibrium:\n",
    "                    equilibrium[player] = {}\n",
    "                \n",
    "                # Store the optimal action for this player at this information set\n",
    "                if node_id in self.optimal_actions:\n",
    "                    equilibrium[player][tuple(path)] = self.optimal_actions[node_id]\n",
    "            \n",
    "            # Continue traversal with the optimal child\n",
    "            if node_id in self.optimal_actions:\n",
    "                optimal_action = self.optimal_actions[node_id]\n",
    "                child_node = node.actions.get(optimal_action)\n",
    "                if child_node:\n",
    "                    traverse(child_node, path + [optimal_action])\n",
    "        \n",
    "        # Start traversal from the root\n",
    "        traverse(self.game.root)\n",
    "        \n",
    "        self.equilibrium = equilibrium\n",
    "        return equilibrium\n",
    "    \n",
    "    def visualize_equilibrium(self):\n",
    "        \"\"\"Visualize the game tree with equilibrium strategies highlighted.\"\"\"\n",
    "        if not self.optimal_actions:\n",
    "            self.solve()\n",
    "            \n",
    "        # Create a new directed graph\n",
    "        graph = nx.DiGraph()\n",
    "        node_labels = {}\n",
    "        \n",
    "        # Add nodes and edges to the graph\n",
    "        def add_nodes_and_edges(node, parent=None, action=None):\n",
    "            node_id = id(node)\n",
    "            \n",
    "            # Create label for the node\n",
    "            if not node.actions:  # Terminal node\n",
    "                label = f\"Payoff: {node.payoff}\"\n",
    "            else:\n",
    "                players_str = \", \".join(sorted(node.players))\n",
    "                optimal = self.optimal_actions.get(node_id, \"N/A\")\n",
    "                label = f\"{players_str}\\nOptimal: {optimal}\"\n",
    "            \n",
    "            node_labels[node_id] = label\n",
    "            graph.add_node(node_id)\n",
    "            \n",
    "            # Add edge from parent if applicable\n",
    "            if parent is not None:\n",
    "                # Check if this edge is part of the equilibrium path\n",
    "                parent_optimal = self.optimal_actions.get(parent)\n",
    "                is_optimal = (parent_optimal == action)\n",
    "                \n",
    "                # Add the edge with attributes\n",
    "                graph.add_edge(parent, node_id, \n",
    "                               action=action,\n",
    "                               color=\"red\" if is_optimal else \"black\",\n",
    "                               width=2.0 if is_optimal else 1.0)\n",
    "            \n",
    "            # Process all children of this node\n",
    "            for act, child in node.actions.items():\n",
    "                add_nodes_and_edges(child, node_id, act)\n",
    "        \n",
    "        # Build the graph starting from the root\n",
    "        add_nodes_and_edges(self.game.root)\n",
    "        \n",
    "        # Draw the graph\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        pos = graphviz_layout(graph, prog=\"dot\")\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(graph, pos, node_size=3000, node_color=\"lightblue\")\n",
    "        nx.draw_networkx_labels(graph, pos, labels=node_labels, font_size=10)\n",
    "        \n",
    "        # Draw edges with appropriate colors and widths\n",
    "        for (u, v, data) in graph.edges(data=True):\n",
    "            nx.draw_networkx_edges(graph, pos, edgelist=[(u, v)], \n",
    "                                  edge_color=data[\"color\"], \n",
    "                                  width=data[\"width\"])\n",
    "        \n",
    "        # Add edge labels\n",
    "        edge_labels = {(u, v): data[\"action\"] for u, v, data in graph.edges(data=True)}\n",
    "        nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_size=8)\n",
    "        \n",
    "        plt.title(\"Game Tree with Equilibrium Path Highlighted\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        \n",
    "    def print_equilibrium(self):\n",
    "        \"\"\"Print the equilibrium strategies in a readable format.\"\"\"\n",
    "        if not self.equilibrium:\n",
    "            self.get_subgame_perfect_equilibrium()\n",
    "        \n",
    "        print(\"Subgame Perfect Equilibrium Strategies:\")\n",
    "        for player, strategies in self.equilibrium.items():\n",
    "            print(f\"Player {player}:\")\n",
    "            for path, action in strategies.items():\n",
    "                path_str = \" → \".join([\"Root\"] + list(path)) if path else \"Root\"\n",
    "                print(f\"  At '{path_str}', choose '{action}'\")\n",
    "        \n",
    "        print(\"\\nEquilibrium Path:\")\n",
    "        node = self.game.root\n",
    "        path = [\"Root\"]\n",
    "        \n",
    "        while node and node.actions:\n",
    "            node_id = id(node)\n",
    "            if node_id in self.optimal_actions:\n",
    "                next_action = self.optimal_actions[node_id]\n",
    "                path.append(next_action)\n",
    "                \n",
    "                # Find the child with this action\n",
    "                node = node.actions.get(next_action)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(\" → \".join(path))\n",
    "        \n",
    "        if node and node.payoff is not None:\n",
    "            print(f\"Terminal payoffs: {node.payoff}\")\n",
    "\n",
    "    def record_equilibrium(self): \n",
    "        \"\"\"Create dictionary of the equilibrium.\"\"\" \n",
    "        if not self.equilibrium:\n",
    "            self.get_subgame_perfect_equilibrium()\n",
    "\n",
    "        player_actions = {}\n",
    "        for player, strategies in self.equilibrium.items():\n",
    "            player_actions[player] = {}\n",
    "            for path, action in strategies.items():\n",
    "                player_actions[player] = action\n",
    "                \n",
    "        return player_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0cc2d3-8bcd-4d90-aaf6-ce9ba6f76dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = BackwardInductionSolver(game)\n",
    "solver.solve() \n",
    "solver.print_equilibrium()\n",
    "solver.visualize_equilibrium()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a95c53-677a-42b9-858e-dbfb113ae8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_trade_war_game():\n",
    "    \"\"\"\n",
    "    Create the trade war game and manually trace through the backward induction algorithm\n",
    "    to verify it works correctly.\n",
    "    \"\"\"\n",
    "    # Create a new game instance\n",
    "    game = Game()\n",
    "    \n",
    "    # Add moves for China and the US\n",
    "    game.add_moves(player=\"China\", actions=[\"Tariff\", \"No Tariff\"])\n",
    "    game.add_moves(player=\"US\", actions=[\"Tariff\", \"No Tariff\"])\n",
    "    \n",
    "    # Define the outcomes/payoffs for the terminal nodes\n",
    "    outcomes = [\n",
    "        (-6, -6),  # Both impose tariffs\n",
    "        (0, -10),  # China tariffs, US does not\n",
    "        (-10, 0),  # China does not tariff, US does\n",
    "        (-1, -1),   # Neither imposes tariffs\n",
    "    ]\n",
    "    game.add_outcomes(outcomes)\n",
    "    \n",
    "    # Print the game structure for verification\n",
    "    print(\"Game Structure:\")\n",
    "    game.display_tree()\n",
    "    \n",
    "    print(\"\\nTerminal nodes and their payoffs:\")\n",
    "    leaf_nodes = []\n",
    "    \n",
    "    def find_leaf_nodes(node):\n",
    "        if not node.actions:\n",
    "            leaf_nodes.append((node, node.payoff))\n",
    "        else:\n",
    "            for action, child in node.actions.items():\n",
    "                find_leaf_nodes(child)\n",
    "    \n",
    "    find_leaf_nodes(game.root)\n",
    "    \n",
    "    for i, (node, payoff) in enumerate(leaf_nodes):\n",
    "        print(f\"Leaf {i+1}: Payoff = {payoff}\")\n",
    "    \n",
    "    # Create solver with debug mode on\n",
    "    print(\"\\nRunning backward induction:\")\n",
    "    solver = BackwardInductionSolver(game)\n",
    "    solver.debug = True\n",
    "    solver.solve()\n",
    "    \n",
    "    print(\"\\nOptimal actions by node ID:\")\n",
    "    for node_id, action in solver.optimal_actions.items():\n",
    "        print(f\"Node {node_id}: {action}\")\n",
    "    \n",
    "    print(\"\\nNode values:\")\n",
    "    for node_id, value in solver.node_values.items():\n",
    "        print(f\"Node {node_id}: {value}\")\n",
    "    \n",
    "    # Get and print equilibrium\n",
    "    equilibrium = solver.get_subgame_perfect_equilibrium()\n",
    "    print(\"\\nSubgame perfect equilibrium:\")\n",
    "    solver.print_equilibrium()\n",
    "    \n",
    "    return game, solver\n",
    "\n",
    "# Run the diagnostic function\n",
    "if __name__ == \"__main__\":\n",
    "    game, solver = debug_trade_war_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbca43d-bde9-4946-b7ce-3909bdfafcae",
   "metadata": {},
   "source": [
    "### Test good stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad1f5f-2c4c-463d-aac9-34ff7628c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Represents a game state, supporting sequential moves.\"\"\"\n",
    "    def __init__(self, players=None):\n",
    "        self.players = players if players else set()\n",
    "        self.actions = {}  # Maps action names to child nodes\n",
    "        self.payoff = None  # Stores outcome if terminal\n",
    "\n",
    "    def add_action(self, action, child_node):\n",
    "        \"\"\"Adds an action leading to a child node.\"\"\"\n",
    "        self.actions[action] = child_node\n",
    "\n",
    "class Game:\n",
    "    \"\"\"Represents a game theory structure with players, actions, and payoffs.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "        self.current_nodes = [self.root]  # Track leaf nodes for expansion\n",
    "        self.players = []  # List to track players in the order they're added\n",
    "        self.player_indices = {}  # Maps player names to their indices\n",
    "    \n",
    "    def add_player(self, player):\n",
    "        \"\"\"Add a player to the game if not already present.\"\"\"\n",
    "        if player not in self.player_indices:\n",
    "            self.players.append(player)\n",
    "            self.player_indices[player] = len(self.players) - 1\n",
    "        return self.player_indices[player]\n",
    "    \n",
    "    def get_player_index(self, player):\n",
    "        \"\"\"Return the index of the player in payoff tuples.\"\"\"\n",
    "        if player not in self.player_indices:\n",
    "            raise ValueError(f\"Player {player} not found in game\")\n",
    "        return self.player_indices[player]\n",
    "    \n",
    "    def add_moves(self, player, actions):\n",
    "        \"\"\"Adds moves for a player at all current leaf nodes.\"\"\"\n",
    "        # Add player to the tracking system if not already added\n",
    "        self.add_player(player)\n",
    "        \n",
    "        new_nodes = []\n",
    "        for node in self.current_nodes:\n",
    "            node.players.add(player)\n",
    "            for action in actions:\n",
    "                child_node = Node()\n",
    "                node.add_action(action, child_node)\n",
    "                new_nodes.append(child_node)\n",
    "        self.current_nodes = new_nodes\n",
    "    \n",
    "    def add_outcomes(self, outcomes):\n",
    "        \"\"\"Assigns payoffs to the current leaf nodes.\"\"\"\n",
    "        if len(outcomes) != len(self.current_nodes):\n",
    "            raise ValueError(\"Number of outcomes must match the number of terminal nodes.\")\n",
    "        for node, payoff in zip(self.current_nodes, outcomes):\n",
    "            node.payoff = payoff\n",
    "    \n",
    "    def display_tree(self):\n",
    "        \"\"\"Recursively prints the game tree.\"\"\"\n",
    "        def recurse(node, depth=0):\n",
    "            payoff_text = f\", Payoff: {node.payoff}\" if node.payoff is not None else \"\"\n",
    "            print(\"  \" * depth + f\"Players: {node.players}{payoff_text}\")\n",
    "            for action, child in node.actions.items():\n",
    "                print(\"  \" * depth + f\"Action: {action}\")\n",
    "                recurse(child, depth + 1)\n",
    "        recurse(self.root)\n",
    "    \n",
    "    def visualize_tree(self):\n",
    "        \"\"\"Visualizes the game tree with improved spacing using Graphviz.\"\"\"\n",
    "        graph = nx.DiGraph()\n",
    "        node_labels = {}\n",
    "        \n",
    "        def add_edges(node, parent=None, action_label=None):\n",
    "            \"\"\"Recursively add nodes and edges to the graph.\"\"\"\n",
    "            node_id = id(node)  # Unique identifier\n",
    "            label = f\"{', '.join(node.players)}\" if node.actions else f\"Payoff: {node.payoff}\"\n",
    "            node_labels[node_id] = label\n",
    "\n",
    "            if parent is not None:\n",
    "                graph.add_edge(parent, node_id, action=action_label)\n",
    "\n",
    "            for action, child in node.actions.items():\n",
    "                add_edges(child, node_id, action)\n",
    "\n",
    "        add_edges(self.root)\n",
    "\n",
    "        # Use Graphviz DOT layout for better hierarchy\n",
    "        pos = graphviz_layout(graph, prog=\"dot\")\n",
    "\n",
    "        # Draw graph\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        nx.draw(graph, pos, with_labels=True, labels=node_labels, node_color=\"lightblue\", edge_color=\"black\", \n",
    "                node_size=3000, font_size=8, font_weight=\"bold\", arrowsize=15)\n",
    "\n",
    "        # Add action labels on edges\n",
    "        edge_labels = {(u, v): data[\"action\"] for u, v, data in graph.edges(data=True)}\n",
    "        nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_size=8, \n",
    "                                     bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.8))\n",
    "\n",
    "        plt.title(\"Game Tree Visualization\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f056f6-9d9c-44be-b1d6-349c9a6f200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, game):\n",
    "        \"\"\"Initialize with a game instance.\"\"\"\n",
    "        if not isinstance(game, Game):\n",
    "            raise TypeError(\"Solver expects an instance of Game.\")\n",
    "        self.game = game\n",
    "        self.equilibrium = {}\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"Base method to be overridden by specific solvers.\"\"\"\n",
    "        raise NotImplementedError(\"Solve method must be implemented in subclasses.\")\n",
    "\n",
    "    def get_equilibrium(self):\n",
    "        \"\"\"Return the computed equilibrium.\"\"\"\n",
    "        return self.equilibrium\n",
    "        \n",
    "class BackwardInductionSolver(Solver):\n",
    "    def __init__(self, game):\n",
    "        \"\"\"Initialize the backward induction solver with a game.\"\"\"\n",
    "        super().__init__(game)\n",
    "        self.optimal_actions = {}  # Dictionary to store optimal actions at each node\n",
    "        self.node_values = {}      # Dictionary to store computed values for each node\n",
    "        # Debug mode to print detailed information during solving\n",
    "        self.debug = False\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"Solve the game using backward induction.\"\"\"\n",
    "        # Start from the root and solve recursively\n",
    "        self._backward_induction(self.game.root)           \n",
    "        return self.optimal_actions\n",
    "\n",
    "    def _backward_induction(self, node, depth=0):\n",
    "        \"\"\"\n",
    "        Recursive backward induction algorithm.\n",
    "        Returns the value (payoff) of the current node.\n",
    "        \n",
    "        Parameters:\n",
    "        node: Current game node\n",
    "        depth: Current depth in the tree (for debugging)\n",
    "        \"\"\"\n",
    "        node_id = id(node)\n",
    "        \n",
    "        # Base case: terminal node (no actions)\n",
    "        if not node.actions:\n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + f\"Terminal node with payoff: {node.payoff}\")\n",
    "            self.node_values[node_id] = node.payoff\n",
    "            return node.payoff\n",
    "        \n",
    "        # Get the player making the decision at this node\n",
    "        if not node.players:\n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + \"No players at this node\")\n",
    "            return None\n",
    "        \n",
    "        current_player = next(iter(node.players))\n",
    "        if self.debug:\n",
    "            print(\"  \" * depth + f\"Player {current_player} at depth {depth}\")\n",
    "        \n",
    "        # Use the game's player indexing system instead of hardcoded values\n",
    "        player_idx = self.game.get_player_index(current_player)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"  \" * depth + f\"Player index: {player_idx}\")\n",
    "        \n",
    "        # Get values of all children\n",
    "        best_payoff = float('-inf')\n",
    "        best_action = None\n",
    "        best_value = None\n",
    "        \n",
    "        for action, child_node in node.actions.items():\n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + f\"Trying action: {action}\")\n",
    "            \n",
    "            child_value = self._backward_induction(child_node, depth + 1)\n",
    "            \n",
    "            if child_value is None:\n",
    "                continue\n",
    "            \n",
    "            # Extract the current player's payoff from the tuple\n",
    "            player_payoff = child_value[player_idx]\n",
    "            \n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + f\"Action {action} gives payoff {player_payoff} to {current_player}\")\n",
    "            \n",
    "            if player_payoff > best_payoff:\n",
    "                best_payoff = player_payoff\n",
    "                best_action = action\n",
    "                best_value = child_value\n",
    "                \n",
    "                if self.debug:\n",
    "                    print(\"  \" * depth + f\"New best action: {best_action} with payoff {best_payoff}\")\n",
    "        \n",
    "        # Store optimal action for this node\n",
    "        if best_action is not None:\n",
    "            self.optimal_actions[node_id] = best_action\n",
    "            if self.debug:\n",
    "                print(\"  \" * depth + f\"Optimal action for node {node_id}: {best_action}\")\n",
    "        \n",
    "        # Store node value\n",
    "        self.node_values[node_id] = best_value\n",
    "        \n",
    "        return best_value\n",
    "\n",
    "    def get_subgame_perfect_equilibrium(self):\n",
    "        \"\"\"Return the subgame perfect equilibrium strategies.\"\"\"\n",
    "        if not self.optimal_actions:\n",
    "            self.solve()\n",
    "        \n",
    "        # Format the equilibrium strategies by player\n",
    "        equilibrium = {}\n",
    "        \n",
    "        # Traverse the tree to determine which nodes are reachable\n",
    "        def traverse(node, path=[]):\n",
    "            node_id = id(node)\n",
    "            \n",
    "            # Skip terminal nodes\n",
    "            if not node.actions:\n",
    "                return\n",
    "            \n",
    "            # For each player at this node, record their optimal action\n",
    "            for player in node.players:\n",
    "                if player not in equilibrium:\n",
    "                    equilibrium[player] = {}\n",
    "                \n",
    "                # Store the optimal action for this player at this information set\n",
    "                if node_id in self.optimal_actions:\n",
    "                    equilibrium[player][tuple(path)] = self.optimal_actions[node_id]\n",
    "            \n",
    "            # Continue traversal with the optimal child\n",
    "            if node_id in self.optimal_actions:\n",
    "                optimal_action = self.optimal_actions[node_id]\n",
    "                child_node = node.actions.get(optimal_action)\n",
    "                if child_node:\n",
    "                    traverse(child_node, path + [optimal_action])\n",
    "        \n",
    "        # Start traversal from the root\n",
    "        traverse(self.game.root)\n",
    "        \n",
    "        self.equilibrium = equilibrium\n",
    "        return equilibrium\n",
    "    \n",
    "    def visualize_equilibrium(self):\n",
    "        \"\"\"Visualize the game tree with equilibrium strategies highlighted.\"\"\"\n",
    "        if not self.optimal_actions:\n",
    "            self.solve()\n",
    "            \n",
    "        # Create a new directed graph\n",
    "        graph = nx.DiGraph()\n",
    "        node_labels = {}\n",
    "        \n",
    "        # Add nodes and edges to the graph\n",
    "        def add_nodes_and_edges(node, parent=None, action=None):\n",
    "            node_id = id(node)\n",
    "            \n",
    "            # Create label for the node\n",
    "            if not node.actions:  # Terminal node\n",
    "                label = f\"Payoff: {node.payoff}\"\n",
    "            else:\n",
    "                players_str = \", \".join(sorted(node.players))\n",
    "                optimal = self.optimal_actions.get(node_id, \"N/A\")\n",
    "                label = f\"{players_str}\\nOptimal: {optimal}\"\n",
    "            \n",
    "            node_labels[node_id] = label\n",
    "            graph.add_node(node_id)\n",
    "            \n",
    "            # Add edge from parent if applicable\n",
    "            if parent is not None:\n",
    "                # Check if this edge is part of the equilibrium path\n",
    "                parent_optimal = self.optimal_actions.get(parent)\n",
    "                is_optimal = (parent_optimal == action)\n",
    "                \n",
    "                # Add the edge with attributes\n",
    "                graph.add_edge(parent, node_id, \n",
    "                               action=action,\n",
    "                               color=\"red\" if is_optimal else \"black\",\n",
    "                               width=2.0 if is_optimal else 1.0)\n",
    "            \n",
    "            # Process all children of this node\n",
    "            for act, child in node.actions.items():\n",
    "                add_nodes_and_edges(child, node_id, act)\n",
    "        \n",
    "        # Build the graph starting from the root\n",
    "        add_nodes_and_edges(self.game.root)\n",
    "        \n",
    "        # Draw the graph\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        pos = graphviz_layout(graph, prog=\"dot\")\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(graph, pos, node_size=3000, node_color=\"lightblue\")\n",
    "        nx.draw_networkx_labels(graph, pos, labels=node_labels, font_size=10)\n",
    "        \n",
    "        # Draw edges with appropriate colors and widths\n",
    "        for (u, v, data) in graph.edges(data=True):\n",
    "            nx.draw_networkx_edges(graph, pos, edgelist=[(u, v)], \n",
    "                                  edge_color=data[\"color\"], \n",
    "                                  width=data[\"width\"])\n",
    "        \n",
    "        # Add edge labels\n",
    "        edge_labels = {(u, v): data[\"action\"] for u, v, data in graph.edges(data=True)}\n",
    "        nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_size=8)\n",
    "        \n",
    "        plt.title(\"Game Tree with Equilibrium Path Highlighted\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        \n",
    "    def print_equilibrium(self):\n",
    "        \"\"\"Print the equilibrium strategies in a readable format.\"\"\"\n",
    "        if not self.equilibrium:\n",
    "            self.get_subgame_perfect_equilibrium()\n",
    "        \n",
    "        print(\"Subgame Perfect Equilibrium Strategies:\")\n",
    "        for player, strategies in self.equilibrium.items():\n",
    "            print(f\"Player {player}:\")\n",
    "            for path, action in strategies.items():\n",
    "                path_str = \" → \".join([\"Root\"] + list(path)) if path else \"Root\"\n",
    "                print(f\"  At '{path_str}', choose '{action}'\")\n",
    "        \n",
    "        print(\"\\nEquilibrium Path:\")\n",
    "        node = self.game.root\n",
    "        path = [\"Root\"]\n",
    "        \n",
    "        while node and node.actions:\n",
    "            node_id = id(node)\n",
    "            if node_id in self.optimal_actions:\n",
    "                next_action = self.optimal_actions[node_id]\n",
    "                path.append(next_action)\n",
    "                \n",
    "                # Find the child with this action\n",
    "                node = node.actions.get(next_action)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(\" → \".join(path))\n",
    "        \n",
    "        if node and node.payoff is not None:\n",
    "            print(f\"Terminal payoffs: {node.payoff}\")\n",
    "\n",
    "    def record_equilibrium(self): \n",
    "        \"\"\"Create dictionary of the equilibrium.\"\"\" \n",
    "        if not self.equilibrium:\n",
    "            self.get_subgame_perfect_equilibrium()\n",
    "\n",
    "        player_actions = {}\n",
    "        for player, strategies in self.equilibrium.items():\n",
    "            player_actions[player] = {}\n",
    "            for path, action in strategies.items():\n",
    "                player_actions[player] = action\n",
    "                \n",
    "        return player_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0d325-83c3-492d-a20d-9ea6df846d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "\n",
    "# Add players and their actions\n",
    "game.add_moves(\"China\", [\"Tariff\", \"No Tariff\"])\n",
    "game.add_moves(\"US\", [\"Tariff\", \"No Tariff\"])\n",
    "\n",
    "# Add payoffs for all terminal nodes\n",
    "# Order matters! The payoffs correspond to the order players were added\n",
    "# For example: (China's payoff, US's payoff)\n",
    "# Define the outcomes/payoffs for the terminal nodes\n",
    "\n",
    "outcomes = [\n",
    "    (-6, -6),  # Both impose tariffs\n",
    "    (0, -10),  # China tariffs, US does not\n",
    "    (-10, 0),  # China does not tariff, US does\n",
    "    (-1, -1),   # Neither imposes tariffs\n",
    "]\n",
    "game.add_outcomes(outcomes)\n",
    "\n",
    "# Create and run solver\n",
    "solver = BackwardInductionSolver(game)\n",
    "solver.solve()\n",
    "solver.print_equilibrium()\n",
    "\n",
    "# We can check player indices\n",
    "print(f\"China's index: {game.get_player_index('China')}\")  # Should print 0\n",
    "print(f\"US's index: {game.get_player_index('US')}\")       # Should print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e44a3-40e5-41be-a01d-bae9f6be8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.visualize_equilibrium()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58638dd3-2e8a-4cc5-9148-7e4785a76409",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "\n",
    "# Add players and their actions\n",
    "game.add_moves(\"China\", [\"Tariff\", \"No Tariff\"])\n",
    "game.add_moves(\"US\", [\"Tariff\", \"No Tariff\"])\n",
    "game.add_moves(\"Europe\", [\"Tariff\", \"No Tariff\"])\n",
    "\n",
    "# Add payoffs for all terminal nodes\n",
    "# Order matters! The payoffs correspond to the order players were added\n",
    "# For example: (China's payoff, US's payoff)\n",
    "# Define the outcomes/payoffs for the terminal nodes\n",
    "\n",
    "outcomes = [\n",
    "    (-6, -6, -6),  # Both impose tariffs\n",
    "    (0, -10, -10),  # China tariffs, US does not\n",
    "    (-10, 0, 0),  # China does not tariff, US does\n",
    "    (-1, -1, -1),   # Neither imposes tariffs\n",
    "    (-6, -6, -6),  # Both impose tariffs\n",
    "    (0, -10, -10),  # China tariffs, US does not\n",
    "    (-10, 0, 0),  # China does not tariff, US does\n",
    "    (-1, -1, -1),   # Neither imposes tariffs\n",
    "]\n",
    "game.add_outcomes(outcomes)\n",
    "\n",
    "# Create and run solver\n",
    "solver = BackwardInductionSolver(game)\n",
    "solver.solve()\n",
    "solver.print_equilibrium()\n",
    "\n",
    "# We can check player indices\n",
    "print(f\"China's index: {game.get_player_index('China')}\")  # Should print 0\n",
    "print(f\"US's index: {game.get_player_index('US')}\")       # Should print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12ad80-0c19-499f-9600-18fed107c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.visualize_equilibrium() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a07917-e4d2-46e0-953b-4796f2124df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
