{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee51d34-d294-4df7-a377-e26eafbde3d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.solver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgame\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Game\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Solver\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m product\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.solver'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.game import Game\n",
    "from src.solver import Solver\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383b45d-78bb-4191-a8c4-6e13097c4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "\n",
    "# Add players and their actions\n",
    "game.add_moves(\"China\", [\"Tariff\", \"No Tariff\"])\n",
    "game.add_moves(\"US\", [\"Tariff\", \"No Tariff\"])\n",
    "\n",
    "# Add payoffs for all terminal nodes\n",
    "# Order matters! The payoffs correspond to the order players were added\n",
    "# For example: (China's payoff, US's payoff)\n",
    "# Define the outcomes/payoffs for the terminal nodes\n",
    "\n",
    "outcomes = [\n",
    "    (-6, -6),  # Both impose tariffs\n",
    "    (0, -10),  # China tariffs, US does not\n",
    "    (-10, 0),  # China does not tariff, US does\n",
    "    (-1, -1),   # Neither imposes tariffs\n",
    "]\n",
    "game.add_outcomes(outcomes)\n",
    "\n",
    "# We can check player indices\n",
    "print(f\"China's index: {game.get_player_index('China')}\")  # Should print 0\n",
    "print(f\"US's index: {game.get_player_index('US')}\")       # Should print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951937b-544e-42a9-b619-c3f3c2323f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.visualize_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88b562-5b48-410b-af14-d7168a7ecfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PureStrategyNashSolver(Solver):\n",
    "    def __init__(self, game):\n",
    "        \"\"\"Initialize the Pure Strategy Nash solver with a game.\"\"\"\n",
    "        super().__init__(game)\n",
    "        self.debug = False\n",
    "        self.equilibria = []  # Store all found Nash equilibria\n",
    "        self.strategy_profiles = {}  # Store all possible strategy profiles\n",
    "        self.payoff_matrix = {}  # Store payoffs for each strategy profile\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"\n",
    "        Solve the game to find all Pure Strategy Nash Equilibria.\n",
    "        Returns a list of equilibria, where each equilibrium is a dictionary\n",
    "        mapping players to their equilibrium strategies.\n",
    "        \"\"\"\n",
    "        # Generate all possible strategy profiles\n",
    "        self._generate_strategy_profiles()\n",
    "        \n",
    "        # Compute payoffs for each strategy profile\n",
    "        self._compute_payoffs()\n",
    "        \n",
    "        # Find Nash equilibria\n",
    "        self._find_nash_equilibria()\n",
    "        \n",
    "        # Store the first equilibrium in self.equilibrium for compatibility\n",
    "        if self.equilibria:\n",
    "            self.equilibrium = self.equilibria[0]\n",
    "        else:\n",
    "            self.equilibrium = {}\n",
    "            \n",
    "        return self.equilibria\n",
    "\n",
    "    def _generate_strategy_profiles(self):\n",
    "        \"\"\"Generate all possible pure strategy profiles for the game.\"\"\"\n",
    "        # Use game.players attribute instead of get_all_players()\n",
    "        players = self.game.players\n",
    "        \n",
    "        # Find all available actions for each player\n",
    "        player_actions = {}\n",
    "        for player in players:\n",
    "            # Collect all possible actions for this player\n",
    "            actions = self._collect_player_actions(player)\n",
    "            if actions:\n",
    "                player_actions[player] = actions\n",
    "                \n",
    "        if self.debug:\n",
    "            print(f\"Player actions: {player_actions}\")\n",
    "            \n",
    "        # Generate all possible strategy profiles using Cartesian product\n",
    "        action_items = list(player_actions.items())\n",
    "        players_list = [p for p, _ in action_items]\n",
    "        action_lists = [actions for _, actions in action_items]\n",
    "        \n",
    "        # Generate all combinations of actions\n",
    "        for actions_combo in product(*action_lists):\n",
    "            strategy = {players_list[i]: action for i, action in enumerate(actions_combo)}\n",
    "            strategy_key = self._strategy_to_key(strategy)\n",
    "            self.strategy_profiles[strategy_key] = strategy\n",
    "            \n",
    "        if self.debug:\n",
    "            print(f\"Generated {len(self.strategy_profiles)} strategy profiles\")\n",
    "\n",
    "    def _collect_player_actions(self, player):\n",
    "        \"\"\"Collect all possible actions for a player throughout the game tree.\"\"\"\n",
    "        actions = set()\n",
    "        \n",
    "        def traverse(node):\n",
    "            # If player is active at this node, collect their actions\n",
    "            if player in node.players:\n",
    "                actions.update(node.actions.keys())\n",
    "                \n",
    "            # Continue traversal for all children\n",
    "            for child in node.actions.values():\n",
    "                traverse(child)\n",
    "        \n",
    "        # Start traversal from the root\n",
    "        traverse(self.game.root)\n",
    "        return list(actions)\n",
    "\n",
    "    def _compute_payoffs(self):\n",
    "        \"\"\"Compute payoffs for each strategy profile.\"\"\"\n",
    "        for strategy_key, strategy in self.strategy_profiles.items():\n",
    "            # Simulate the game with this strategy profile\n",
    "            payoffs = self._simulate_game(strategy)\n",
    "            self.payoff_matrix[strategy_key] = payoffs\n",
    "            \n",
    "            if self.debug:\n",
    "                print(f\"Strategy {strategy_key} yields payoffs {payoffs}\")\n",
    "\n",
    "    def _simulate_game(self, strategy):\n",
    "        \"\"\"\n",
    "        Simulate the game with a given strategy profile and return the payoffs.\n",
    "        \n",
    "        Parameters:\n",
    "        strategy: Dictionary mapping players to their chosen actions\n",
    "        \n",
    "        Returns:\n",
    "        Tuple of payoffs for all players\n",
    "        \"\"\"\n",
    "        # Start at the root node\n",
    "        node = self.game.root\n",
    "        \n",
    "        # Follow the game tree according to the strategy profile\n",
    "        while node and node.actions:\n",
    "            # If no players at this node, break\n",
    "            if not node.players:\n",
    "                break\n",
    "                \n",
    "            # Get the player making the decision at this node\n",
    "            current_player = next(iter(node.players))\n",
    "            \n",
    "            # Get the action for this player from the strategy profile\n",
    "            if current_player in strategy:\n",
    "                action = strategy[current_player]\n",
    "                \n",
    "                # Check if this action is available at this node\n",
    "                if action in node.actions:\n",
    "                    # Move to the next node according to the strategy\n",
    "                    node = node.actions[action]\n",
    "                else:\n",
    "                    # Action not available, break the simulation\n",
    "                    if self.debug:\n",
    "                        print(f\"Invalid action {action} for player {current_player} at node\")\n",
    "                    return None\n",
    "            else:\n",
    "                # No strategy defined for this player\n",
    "                if self.debug:\n",
    "                    print(f\"No strategy defined for player {current_player}\")\n",
    "                return None\n",
    "        \n",
    "        # Return the payoffs at the terminal node\n",
    "        return node.payoff if node else None\n",
    "\n",
    "    def _find_nash_equilibria(self):\n",
    "        \"\"\"\n",
    "        Find all Pure Strategy Nash Equilibria.\n",
    "        A strategy profile is a Nash equilibrium if no player can improve\n",
    "        their payoff by unilaterally changing their strategy.\n",
    "        \"\"\"\n",
    "        players = self.game.players\n",
    "        player_indices = {player: self.game.get_player_index(player) for player in players}\n",
    "        \n",
    "        for strategy_key, strategy in self.strategy_profiles.items():\n",
    "            is_nash = True\n",
    "            payoffs = self.payoff_matrix.get(strategy_key)\n",
    "            \n",
    "            # Skip if this strategy profile doesn't have valid payoffs\n",
    "            if payoffs is None:\n",
    "                continue\n",
    "                \n",
    "            # Check if any player can improve by deviating\n",
    "            for player, current_action in strategy.items():\n",
    "                player_idx = player_indices[player]\n",
    "                current_payoff = payoffs[player_idx]\n",
    "                \n",
    "                # Try each alternative action for this player\n",
    "                alternative_actions = self._collect_player_actions(player)\n",
    "                for alt_action in alternative_actions:\n",
    "                    if alt_action == current_action:\n",
    "                        continue\n",
    "                        \n",
    "                    # Create an alternative strategy with this player's action changed\n",
    "                    alt_strategy = strategy.copy()\n",
    "                    alt_strategy[player] = alt_action\n",
    "                    alt_key = self._strategy_to_key(alt_strategy)\n",
    "                    \n",
    "                    # Get payoffs for the alternative strategy\n",
    "                    alt_payoffs = self.payoff_matrix.get(alt_key)\n",
    "                    \n",
    "                    # Skip if this alternative doesn't have valid payoffs\n",
    "                    if alt_payoffs is None:\n",
    "                        continue\n",
    "                        \n",
    "                    # Check if player would get higher payoff by deviating\n",
    "                    alt_payoff = alt_payoffs[player_idx]\n",
    "                    if alt_payoff > current_payoff:\n",
    "                        is_nash = False\n",
    "                        if self.debug:\n",
    "                            print(f\"Not Nash: Player {player} can improve by switching from {current_action} to {alt_action}\")\n",
    "                        break\n",
    "                \n",
    "                if not is_nash:\n",
    "                    break\n",
    "            \n",
    "            # If no player can improve by deviating, it's a Nash equilibrium\n",
    "            if is_nash:\n",
    "                self.equilibria.append(strategy)\n",
    "                if self.debug:\n",
    "                    print(f\"Found Nash equilibrium: {strategy}\")\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Found {len(self.equilibria)} Nash equilibria\")\n",
    "\n",
    "    def _strategy_to_key(self, strategy):\n",
    "        \"\"\"Convert a strategy profile to a hashable key.\"\"\"\n",
    "        # Sort by player to ensure consistent key generation\n",
    "        return tuple(sorted((player, action) for player, action in strategy.items()))\n",
    "        \n",
    "    def get_player_at_index(self, index):\n",
    "        \"\"\"Get player name from index.\"\"\"\n",
    "        if 0 <= index < len(self.game.players):\n",
    "            return self.game.players[index]\n",
    "        return f\"Player{index}\"\n",
    "\n",
    "    def print_equilibria(self):\n",
    "        \"\"\"Print all found Nash equilibria in a readable format.\"\"\"\n",
    "        if not self.equilibria:\n",
    "            self.solve()\n",
    "            \n",
    "        print(f\"Found {len(self.equilibria)} Pure Strategy Nash Equilibria:\")\n",
    "        \n",
    "        for i, eq in enumerate(self.equilibria):\n",
    "            print(f\"\\nEquilibrium {i+1}:\")\n",
    "            for player, action in eq.items():\n",
    "                print(f\"  Player {player}: {action}\")\n",
    "                \n",
    "            # Print payoffs for this equilibrium\n",
    "            eq_key = self._strategy_to_key(eq)\n",
    "            payoffs = self.payoff_matrix.get(eq_key)\n",
    "            if payoffs:\n",
    "                payoff_str = \", \".join(f\"{self.get_player_at_index(i)}: {p}\" \n",
    "                                     for i, p in enumerate(payoffs))\n",
    "                print(f\"  Payoffs: {payoff_str}\")\n",
    "\n",
    "    def visualize_equilibria(self, highlight_index=0):\n",
    "        \"\"\"\n",
    "        Visualize the Nash equilibria as a strategic form grid with the specified \n",
    "        equilibrium highlighted.\n",
    "        \n",
    "        Parameters:\n",
    "        highlight_index: Index of the equilibrium to highlight (default: first equilibrium)\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.equilibria:\n",
    "            self.solve()\n",
    "            \n",
    "        if not self.equilibria:\n",
    "            print(\"No Nash equilibria found to visualize.\")\n",
    "            return\n",
    "            \n",
    "        if highlight_index >= len(self.equilibria):\n",
    "            highlight_index = 0\n",
    "            \n",
    "        # Get the equilibrium to highlight\n",
    "        highlight_eq = self.equilibria[highlight_index]\n",
    "        \n",
    "        # Extract player information from the game\n",
    "        players = self.game.players\n",
    "        \n",
    "        # Group players by their available actions\n",
    "        player_actions = {}\n",
    "        for player in players:\n",
    "            actions = self._collect_player_actions(player)\n",
    "            if actions:\n",
    "                player_actions[player] = actions\n",
    "        \n",
    "        if len(player_actions) <= 2:\n",
    "            # For 2-player games, create a standard grid visualization\n",
    "            self._visualize_two_player_grid(player_actions, highlight_eq, highlight_index)\n",
    "        else:\n",
    "            # For games with more than 2 players, create a tabular visualization\n",
    "            self._visualize_multi_player_table(player_actions, highlight_eq, highlight_index)\n",
    "            \n",
    "    def _visualize_two_player_grid(self, player_actions, highlight_eq, highlight_index):\n",
    "        \"\"\"Create a grid visualization for a 2-player game with combined payoffs and no heatmap.\n",
    "        Player 1 is on the right axis (vertical) and Player 2 is on the top axis (horizontal).\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.colors as mcolors\n",
    "        import numpy as np\n",
    "        \n",
    "        plt.figure(figsize=(6, 4))\n",
    "        \n",
    "        # Get the two players\n",
    "        players = list(player_actions.keys())\n",
    "        if len(players) < 2:\n",
    "            print(\"Not enough players with actions to visualize as a grid.\")\n",
    "            return\n",
    "        \n",
    "        player1, player2 = players[0], players[1]\n",
    "        actions1 = player_actions[player1]\n",
    "        actions2 = player_actions[player2]\n",
    "        \n",
    "        # Create a grid with player 2 actions as columns (horizontal) and \n",
    "        # player 1 actions as rows (vertical)\n",
    "        nrows, ncols = len(actions1), len(actions2)\n",
    "        \n",
    "        # Track Nash equilibria positions\n",
    "        nash_positions = []\n",
    "        highlight_position = None\n",
    "        \n",
    "        # Create a matrix to store cell data (payoff values as strings)\n",
    "        cell_texts = np.empty((nrows, ncols), dtype=object)\n",
    "        cell_colors = np.full((nrows, ncols), 'white', dtype=object)\n",
    "        \n",
    "        # Build payoff matrices\n",
    "        for i, action2 in enumerate(actions2):  # Columns - player 2\n",
    "            for j, action1 in enumerate(actions1):  # Rows - player 1\n",
    "                strategy = {player1: action1, player2: action2}\n",
    "                strategy_key = self._strategy_to_key(strategy)\n",
    "                payoffs = self.payoff_matrix.get(strategy_key)\n",
    "                \n",
    "                # Skip if strategy doesn't have valid payoffs\n",
    "                if payoffs is None:\n",
    "                    cell_texts[j, i] = \"N/A\"\n",
    "                    continue\n",
    "                    \n",
    "                # Get player indices\n",
    "                p1_idx = self.game.get_player_index(player1)\n",
    "                p2_idx = self.game.get_player_index(player2)\n",
    "                \n",
    "                # Store payoffs as a formatted string: \"p1_payoff, p2_payoff\"\n",
    "                cell_texts[j, i] = f\"{payoffs[p1_idx]:.1f}, {payoffs[p2_idx]:.1f}\"\n",
    "                \n",
    "                # Check if this is a Nash equilibrium\n",
    "                is_nash = False\n",
    "                for eq in self.equilibria:\n",
    "                    if eq.get(player1) == action1 and eq.get(player2) == action2:\n",
    "                        is_nash = True\n",
    "                        nash_positions.append((j, i))\n",
    "                        if eq == highlight_eq:\n",
    "                            highlight_position = (j, i)\n",
    "                            cell_colors[j, i] = 'lightgreen'  # Shade highlighted equilibrium green\n",
    "                        elif is_nash:\n",
    "                            cell_colors[j, i] = 'lightblue'  # Shade other equilibria blue\n",
    "                        break\n",
    "        \n",
    "        # Create the plot\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Set up the grid dimensions\n",
    "        ax.set_xlim(-0.5, ncols - 0.5)\n",
    "        ax.set_ylim(-0.5, nrows - 0.5)\n",
    "        \n",
    "        # Set ticks and labels\n",
    "        ax.set_xticks(np.arange(len(actions2)))\n",
    "        ax.set_yticks(np.arange(len(actions1)))\n",
    "        ax.set_xticklabels(actions2)\n",
    "        ax.set_yticklabels(actions1)\n",
    "        \n",
    "        # Important: Invert the y-axis to put player 2 at the top\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        # Rotate the tick labels and set alignment\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, len(actions2), 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, len(actions1), 1), minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"black\", linestyle='-', linewidth=1)\n",
    "        \n",
    "        # Add cell backgrounds\n",
    "        for i in range(ncols):\n",
    "            for j in range(nrows):\n",
    "                rect = plt.Rectangle((i - 0.5, j - 0.5), 1, 1, fill=True, \n",
    "                                    color=cell_colors[j, i], alpha=0.3)\n",
    "                ax.add_patch(rect)\n",
    "        \n",
    "        # Add text annotations for payoffs\n",
    "        for i in range(ncols):\n",
    "            for j in range(nrows):\n",
    "                if cell_texts[j, i] != \"N/A\":\n",
    "                    ax.text(i, j, cell_texts[j, i], ha=\"center\", va=\"center\", fontsize=10)\n",
    "        \n",
    "        # Highlight the selected equilibrium with a bold border\n",
    "        if highlight_position:\n",
    "            rect = plt.Rectangle((highlight_position[1] - 0.5, highlight_position[0] - 0.5), 1, 1, \n",
    "                               fill=False, edgecolor='green', linewidth=3)\n",
    "            ax.add_patch(rect)\n",
    "        \n",
    "        # Add title and labels - position the labels on the top and right\n",
    "        plt.title(f\"Nash Equilibrium {highlight_index+1} of {len(self.equilibria)}\")\n",
    "        \n",
    "        # Move x-axis label to top\n",
    "        ax.xaxis.set_label_position('top')\n",
    "        ax.xaxis.tick_top()\n",
    "        \n",
    "        # Set labels\n",
    "        plt.xlabel(f\"Player {player2} Actions\")\n",
    "        plt.ylabel(f\"Player {player1} Actions\")\n",
    "        \n",
    "        # Simplified legend with only Nash Equilibrium\n",
    "        legend_elements = [\n",
    "            plt.Rectangle((0, 0), 1, 1, facecolor='lightblue', alpha=0.3, edgecolor='black', \n",
    "                         label='Nash Equilibrium')\n",
    "        ]\n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    ## See if this needs to be fixed\n",
    "    def _visualize_multi_player_table(self, player_actions, highlight_eq, highlight_index):\n",
    "        \"\"\"Create a grid-style visualization for games with more than 2 players.\"\"\"\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.colors as mcolors\n",
    "        import numpy as np\n",
    "        from matplotlib.patches import Rectangle\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Get all strategy profiles\n",
    "        profiles = sorted(self.strategy_profiles.values(), \n",
    "                        key=lambda s: tuple(s.get(p, '') for p in self.game.players))\n",
    "        \n",
    "        # Filter out profiles without valid payoffs\n",
    "        valid_profiles = []\n",
    "        for strategy in profiles:\n",
    "            strategy_key = self._strategy_to_key(strategy)\n",
    "            payoffs = self.payoff_matrix.get(strategy_key)\n",
    "            if payoffs is not None:\n",
    "                valid_profiles.append((strategy, payoffs))\n",
    "        \n",
    "        # If no valid profiles, show a message\n",
    "        if not valid_profiles:\n",
    "            plt.text(0.5, 0.5, \"No valid strategy profiles to display\", \n",
    "                   ha='center', va='center', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            return\n",
    "        \n",
    "        # Create grid data\n",
    "        num_rows = len(valid_profiles)\n",
    "        num_cols = len(self.game.players) * 2   # Action + Payoff for each player + Equilibrium column\n",
    "        \n",
    "        # Prepare data arrays\n",
    "        cell_texts = np.empty((num_rows, num_cols), dtype=object)\n",
    "        cell_colors = np.full((num_rows, num_cols), 'white', dtype=object)\n",
    "        \n",
    "        # Column labels\n",
    "        col_labels = []\n",
    "        for player in self.game.players:\n",
    "            col_labels.append(f\"{player} Action\")\n",
    "            col_labels.append(f\"{player} Payoff\")\n",
    "        \n",
    "        # Fill data\n",
    "        for i, (strategy, payoffs) in enumerate(valid_profiles):\n",
    "            col_idx = 0\n",
    "            \n",
    "            # Add actions and payoffs\n",
    "            for j, player in enumerate(self.game.players):\n",
    "                cell_texts[i, col_idx] = strategy.get(player, 'N/A')\n",
    "                col_idx += 1\n",
    "                \n",
    "                # Add payoff\n",
    "                player_idx = self.game.get_player_index(player)\n",
    "                cell_texts[i, col_idx] = f\"{payoffs[player_idx]:.1f}\"\n",
    "                col_idx += 1\n",
    "            \n",
    "            # Determine if this is a Nash equilibrium\n",
    "            is_nash = False\n",
    "            is_highlighted = False\n",
    "            \n",
    "            for eq in self.equilibria:\n",
    "                eq_match = True\n",
    "                for player in self.game.players:\n",
    "                    if eq.get(player) != strategy.get(player):\n",
    "                        eq_match = False\n",
    "                        break\n",
    "                \n",
    "                if eq_match:\n",
    "                    is_nash = True\n",
    "                    if eq == highlight_eq:\n",
    "                        is_highlighted = True\n",
    "                    break\n",
    "            \n",
    "            # Add equilibrium status\n",
    "            if is_highlighted:\n",
    "                # Color the entire row for highlighted equilibrium\n",
    "                for j in range(num_cols):\n",
    "                    cell_colors[i, j] = 'lightgreen'\n",
    "            elif is_nash:\n",
    "                cell_texts[i, col_idx] = \"✓ Nash\"\n",
    "                # Color the entire row for nash equilibrium\n",
    "                for j in range(num_cols):\n",
    "                    cell_colors[i, j] = 'lightblue'\n",
    "        \n",
    "        # Set up the grid dimensions\n",
    "        ax.set_xlim(-0.5, num_cols - 0.5)\n",
    "        ax.set_ylim(-0.5, num_rows - 0.5)\n",
    "        \n",
    "        # Set ticks and labels\n",
    "        ax.set_xticks(np.arange(num_cols))\n",
    "        ax.set_yticks(np.arange(num_rows))\n",
    "        ax.set_xticklabels(col_labels)\n",
    "        \n",
    "        # Create row labels from strategy combinations\n",
    "        row_labels = []\n",
    "        for i, (strategy, _) in enumerate(valid_profiles):\n",
    "            row_labels.append(f\"S{i+1}\")\n",
    "        \n",
    "        ax.set_yticklabels(row_labels)\n",
    "        \n",
    "        # Invert the y-axis to display strategies from top to bottom\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        # Adjust tick label formatting\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=9)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, num_cols, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, num_rows, 1), minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"black\", linestyle='-', linewidth=1)\n",
    "        \n",
    "        # Add cell backgrounds\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_cols):\n",
    "                rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, fill=True, \n",
    "                                    color=cell_colors[i, j], alpha=0.3)\n",
    "                ax.add_patch(rect)\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_cols):\n",
    "                if cell_texts[i, j] is not None:\n",
    "                    ax.text(j, i, cell_texts[i, j], ha=\"center\", va=\"center\", fontsize=9)\n",
    "        \n",
    "        # Highlight the selected equilibrium with a bold border\n",
    "        for i, (strategy, _) in enumerate(valid_profiles):\n",
    "            is_highlighted = True\n",
    "            for player in self.game.players:\n",
    "                if strategy.get(player) != highlight_eq.get(player, None):\n",
    "                    is_highlighted = False\n",
    "                    break\n",
    "            \n",
    "            if is_highlighted:\n",
    "                for j in range(num_cols):\n",
    "                    rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, \n",
    "                                       fill=False, edgecolor='green', linewidth=2)\n",
    "                    ax.add_patch(rect)\n",
    "        \n",
    "        # Add title\n",
    "        plt.title(f\"Nash Equilibrium {highlight_index+1} of {len(self.equilibria)}\")\n",
    "        \n",
    "        # Add legend (only for Nash Equilibrium) outside the plot\n",
    "        # 1. Remove the standard Nash Equilibrium from legend\n",
    "        # 2. Rename \"Highlighted Equilibrium\" to \"Nash Equilibrium\"\n",
    "        # 3. Position it outside the grid\n",
    "        legend_elements = [\n",
    "            plt.Rectangle((0, 0), 1, 1, facecolor='lightgreen', alpha=0.3, edgecolor='black', \n",
    "                         label='Nash Equilibrium')\n",
    "        ]\n",
    "        plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "        \n",
    "        # Add a strategy key explanation below the plot with more space\n",
    "        strategy_key = \"Strategy Key:\"\n",
    "        for i, (strategy, _) in enumerate(valid_profiles):\n",
    "            strategy_str = \", \".join([f\"{p}: {a}\" for p, a in strategy.items()])\n",
    "            strategy_key += f\"\\nS{i+1}: {strategy_str}\"\n",
    "        \n",
    "        # Position the strategy key with more space\n",
    "        plt.figtext(0.01, -0.1, strategy_key, fontsize=8, verticalalignment='top')\n",
    "        \n",
    "        # Adjust layout to make room for the legend on the right and strategy key below\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(right=0.85, bottom=0.25)  # Make room for legend and strategy key\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea2f75-4094-4a7b-80cd-cd9f60e348ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = PureStrategyNashSolver(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e237b1-7b48-4ec3-a9b5-3963211ac553",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5659a9-25cc-4197-b55c-0d3d30dabe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.visualize_equilibria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed146ab-adaf-4655-9b51-41d87c08d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "# Add players and their actions\n",
    "game.add_moves(\"China\", [\"Cooperate\", \"Defect\"])\n",
    "game.add_moves(\"US\", [\"Cooperate\", \"Defect\"])\n",
    "game.add_moves(\"EU\", [\"Cooperate\", \"Defect\"])\n",
    "\n",
    "# Add payoffs for all terminal nodes (8 outcomes for 3 players with 2 actions each)\n",
    "# Order: (China's payoff, US's payoff, EU's payoff)\n",
    "outcomes = [\n",
    "    (2, 2, 2),    # All cooperate\n",
    "    (4, -1, -1),  # China cooperates, US cooperates, EU defects\n",
    "    (4, -1, -1),  # China cooperates, US defects, EU cooperates\n",
    "    (0, -3, -3),  # China cooperates, US defects, EU defects\n",
    "    (-1, 4, -1),  # China defects, US cooperates, EU cooperates\n",
    "    (1, 1, -4),   # China defects, US cooperates, EU defects\n",
    "    (1, -4, 1),   # China defects, US defects, EU cooperates\n",
    "    (-2, -2, -2), # All defect\n",
    "]\n",
    "game.add_outcomes(outcomes)\n",
    "\n",
    "# Solve for Nash equilibria\n",
    "solver = PureStrategyNashSolver(game)\n",
    "solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b5f6c-2af8-47e7-91f3-89b20203cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.visualize_equilibria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab54b09-9f98-4b0d-8e2c-e6987e60322a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
